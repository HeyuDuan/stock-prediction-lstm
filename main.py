# main.py
"""
ä¸»è®­ç»ƒè„šæœ¬ - è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ
"""

import sys
import numpy as np
import tensorflow as tf
from sklearn.model_selection import train_test_split

# è®¾ç½®éšæœºç§å­ä¿è¯å¯å¤ç°æ€§
SEED = 42
np.random.seed(SEED)
tf.random.set_seed(SEED)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append('.')

from config import Config
from src.data_generator import StockDataGenerator
from src.preprocessor import StockPreprocessor
from src.lstm_model import LSTMModel
from src.visualization import StockVisualizer

def setup_environment():
    """è®¾ç½®è¿è¡Œç¯å¢ƒ"""
    print("=" * 60)
    print("ğŸ“ˆ è‚¡ç¥¨ä»·æ ¼é¢„æµ‹ç³»ç»Ÿ - LSTMæ¨¡å‹è®­ç»ƒ")
    print("=" * 60)
    
    # æ£€æŸ¥TensorFlowç‰ˆæœ¬
    print(f"TensorFlowç‰ˆæœ¬: {tf.__version__}")
    print(f"NumPyç‰ˆæœ¬: {np.__version__}")
    
    # æ£€æŸ¥GPUæ˜¯å¦å¯ç”¨
    gpus = tf.config.list_physical_devices('GPU')
    if gpus:
        print(f"âœ… GPUå¯ç”¨: {[gpu.name for gpu in gpus]}")
    else:
        print("âš ï¸  GPUä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")

def generate_or_load_data():
    """ç”Ÿæˆæˆ–åŠ è½½æ•°æ®"""
    print("\n" + "=" * 60)
    print("ğŸ“Š æ•°æ®å‡†å¤‡é˜¶æ®µ")
    print("=" * 60)
    
    try:
        # å°è¯•åŠ è½½å·²æœ‰æ•°æ®
        import pandas as pd
        data = pd.read_csv(Config.DATA_PATH)
        print(f"âœ… ä» {Config.DATA_PATH} åŠ è½½å·²æœ‰æ•°æ®")
        print(f"   æ•°æ®å½¢çŠ¶: {data.shape}")
        
    except FileNotFoundError:
        # ç”Ÿæˆæ–°æ•°æ®
        print("ğŸ“ æœªæ‰¾åˆ°æ•°æ®æ–‡ä»¶ï¼Œç”Ÿæˆæ–°çš„æ¨¡æ‹Ÿæ•°æ®...")
        
        generator = StockDataGenerator(
            initial_price=Config.INITIAL_PRICE,
            trend_slope=Config.TREND_SLOPE,
            volatility=Config.VOLATILITY
        )
        
        # ç”ŸæˆåŸºæœ¬æ•°æ®
        data = generator.generate_stock_data(
            start_date=Config.START_DATE,
            end_date=Config.END_DATE,
            symbol=Config.STOCK_SYMBOL
        )
        
        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡
        data = generator.add_technical_indicators(data)
        
        # ä¿å­˜æ•°æ®
        generator.save_to_csv(data, Config.DATA_PATH)
    
    return data

def prepare_data():
    """å‡†å¤‡è®­ç»ƒå’Œæµ‹è¯•æ•°æ®"""
    print("\n" + "=" * 60)
    print("ğŸ”§ æ•°æ®é¢„å¤„ç†")
    print("=" * 60)
    
    # åˆå§‹åŒ–é¢„å¤„ç†å™¨
    preprocessor = StockPreprocessor(
        lookback_days=Config.LOOKBACK_DAYS,
        feature_columns=Config.FEATURES
    )
    
    # åŠ è½½å¹¶å‡†å¤‡æ•°æ®
    X_train, y_train, X_test, y_test, original_df = preprocessor.load_and_prepare_data(
        Config.DATA_PATH,
        train_split=Config.TRAIN_SPLIT
    )
    
    # è¿›ä¸€æ­¥åˆ†å‰²è®­ç»ƒé›†ä¸ºè®­ç»ƒå’ŒéªŒè¯é›†
    X_train, X_val, y_train, y_val = train_test_split(
        X_train, y_train, 
        test_size=0.1, 
        random_state=SEED
    )
    
    print(f"\nğŸ“ æ•°æ®é›†åˆ†å‰²ç»“æœ:")
    print(f"   è®­ç»ƒé›†: {X_train.shape} (ç”¨äºè®­ç»ƒ)")
    print(f"   éªŒè¯é›†: {X_val.shape} (ç”¨äºéªŒè¯)")
    print(f"   æµ‹è¯•é›†: {X_test.shape} (ç”¨äºæœ€ç»ˆæµ‹è¯•)")
    
    # ä¿å­˜scaler
    preprocessor.save_scaler(Config.SCALER_PATH)
    
    return X_train, y_train, X_val, y_val, X_test, y_test, preprocessor, original_df

def build_and_train_model(X_train, y_train, X_val, y_val):
    """æ„å»ºå’Œè®­ç»ƒæ¨¡å‹"""
    print("\n" + "=" * 60)
    print("ğŸ§  æ¨¡å‹æ„å»ºä¸è®­ç»ƒ")
    print("=" * 60)
    
    # æ„å»ºæ¨¡å‹
    input_shape = (X_train.shape[1], X_train.shape[2])
    lstm_model = LSTMModel(input_shape, Config.MODEL_PATH)
    
    model = lstm_model.build_model(
        lstm_units=[50, 50],
        dropout_rate=Config.DROPOUT_RATE,
        learning_rate=Config.LEARNING_RATE
    )
    
    # è®­ç»ƒæ¨¡å‹
    history = lstm_model.train(
        X_train, y_train,
        X_val, y_val,
        epochs=Config.EPOCHS,
        batch_size=Config.BATCH_SIZE
    )
    
    return lstm_model, history

def evaluate_model(lstm_model, X_test, y_test, preprocessor):
    """è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
    print("\n" + "=" * 60)
    print("ğŸ“ˆ æ¨¡å‹è¯„ä¼°")
    print("=" * 60)
    
    # è¯„ä¼°æ¨¡å‹
    evaluation = lstm_model.evaluate(X_test, y_test)
    
    # è¿›è¡Œé¢„æµ‹
    predictions_scaled = lstm_model.predict(X_test)
    
    # åæ ‡å‡†åŒ–
    predictions = preprocessor.inverse_transform(
        predictions_scaled.reshape(-1, 1)
    ).flatten()
    
    y_test_actual = preprocessor.inverse_transform(
        y_test.reshape(-1, 1)
    ).flatten()
    
    return predictions, y_test_actual, evaluation

def visualize_results(history, y_true, y_pred, original_df):
    """å¯è§†åŒ–ç»“æœ"""
    print("\n" + "=" * 60)
    print("ğŸ¨ ç»“æœå¯è§†åŒ–")
    print("=" * 60)
    
    visualizer = StockVisualizer()
    
    # 1. ç»˜åˆ¶è®­ç»ƒå†å²
    visualizer.plot_training_history(
        history, 
        save_path="static/images/training_history.png"
    )
    
    # 2. ç»˜åˆ¶é¢„æµ‹ç»“æœ
    metrics = visualizer.plot_predictions(
        y_true, y_pred,
        save_path="static/images/predictions.png"
    )
    
    # 3. ç»˜åˆ¶ç‰¹å¾ç›¸å…³æ€§
    visualizer.plot_feature_correlation(
        original_df.select_dtypes(include=[np.number]),
        save_path="static/images/correlation_heatmap.png"
    )
    
    return metrics

def main():
    """ä¸»å‡½æ•°"""
    try:
        # 1. ç¯å¢ƒè®¾ç½®
        setup_environment()
        
        # 2. æ•°æ®å‡†å¤‡
        data = generate_or_load_data()
        
        # 3. æ•°æ®é¢„å¤„ç†
        (X_train, y_train, X_val, y_val, 
         X_test, y_test, preprocessor, original_df) = prepare_data()
        
        # 4. æ„å»ºå’Œè®­ç»ƒæ¨¡å‹
        lstm_model, history = build_and_train_model(X_train, y_train, X_val, y_val)
        
        # 5. è¯„ä¼°æ¨¡å‹
        predictions, y_true, evaluation = evaluate_model(
            lstm_model, X_test, y_test, preprocessor
        )
        
        # 6. å¯è§†åŒ–ç»“æœ
        metrics = visualize_results(history, y_true, predictions, original_df)
        
        # 7. è¾“å‡ºæœ€ç»ˆç»“æœ
        print("\n" + "=" * 60)
        print("ğŸ‰ é¡¹ç›®å®Œæˆ!")
        print("=" * 60)
        print(f"\nğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print(f"   æ•°æ®æ–‡ä»¶: {Config.DATA_PATH}")
        print(f"   æ¨¡å‹æ–‡ä»¶: {Config.MODEL_PATH}")
        print(f"   Scaleræ–‡ä»¶: {Config.SCALER_PATH}")
        print(f"   å¯è§†åŒ–å›¾è¡¨: static/images/")
        
        print(f"\nğŸ“Š æœ€ç»ˆæ¨¡å‹æ€§èƒ½:")
        for metric, value in metrics.items():
            print(f"   {metric.upper()}: {value:.4f}")
        
        print("\nâœ… é¡¹ç›®è¿è¡ŒæˆåŠŸï¼å¯ä»¥å¯åŠ¨Webåº”ç”¨æŸ¥çœ‹äº¤äº’ç•Œé¢ã€‚")
        print("   è¿è¡Œå‘½ä»¤: cd app && python app.py")
        
    except Exception as e:
        print(f"\nâŒ è¿è¡Œå‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())